{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GmQpDu1e1idN"
      },
      "outputs": [],
      "source": [
        "# Importation des bibliothèques nécessaires\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import ssl\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import f1_score\n",
        "import time\n",
        "# Résoudre les problèmes SSL pour télécharger les datasets dans Google Colab\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PIuEBAl62ba4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3272652-5d50-4ddc-f5a3-607a65543c35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.10MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 65.3kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:06<00:00, 244kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 12.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Transformation des images : Conversion en tensor et normalisation\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convertir l'image en tensor\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalisation des images en niveaux de gris\n",
        "])\n",
        "\n",
        "# Téléchargement du jeu de données MNIST (train et test)\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_7menm682pOV"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Définir l'architecture du CNN\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Engp36b63Wkw",
        "outputId": "0db0f3a2-3051-4b13-f612-e9cec82270c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utilisation de l'appareil : cuda\n"
          ]
        }
      ],
      "source": [
        "# Définir le périphérique (GPU si disponible, sinon CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Utilisation de l'appareil : {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "O0qa1fpJ342n"
      },
      "outputs": [],
      "source": [
        "# Créer le modèle et l'envoyer sur le GPU si disponible\n",
        "model = CNN().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dnhtuwl438rv"
      },
      "outputs": [],
      "source": [
        "# Fonction de perte et optimiseur\n",
        "criterion = nn.CrossEntropyLoss()  # Perte pour classification multi-classes\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Optimiseur Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8NBpMPg4DrJ",
        "outputId": "5432414e-394a-4bd2-bc38-466f243f5b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Époque [1/10], Perte: 0.0460, Accuracy: 98.61%, F1 Score: 0.99\n",
            "Époque [2/10], Perte: 0.0336, Accuracy: 98.95%, F1 Score: 0.99\n",
            "Époque [3/10], Perte: 0.0265, Accuracy: 99.14%, F1 Score: 0.99\n",
            "Époque [4/10], Perte: 0.0218, Accuracy: 99.34%, F1 Score: 0.99\n",
            "Époque [5/10], Perte: 0.0201, Accuracy: 99.41%, F1 Score: 0.99\n",
            "Époque [6/10], Perte: 0.0165, Accuracy: 99.51%, F1 Score: 1.00\n",
            "Époque [7/10], Perte: 0.0152, Accuracy: 99.56%, F1 Score: 1.00\n",
            "Époque [8/10], Perte: 0.0170, Accuracy: 99.56%, F1 Score: 1.00\n",
            "Époque [9/10], Perte: 0.0134, Accuracy: 99.62%, F1 Score: 1.00\n",
            "Époque [10/10], Perte: 0.0147, Accuracy: 99.63%, F1 Score: 1.00\n",
            "\n",
            "Temps d'entraînement total : 12.61 minutes\n"
          ]
        }
      ],
      "source": [
        "# Nombre d'époques pour l'entraînement\n",
        "import numpy as np\n",
        "num_epochs = 10\n",
        "# Variables pour calculer les métriques\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "# Enregistrer le temps d'entraînement total\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Passer le modèle en mode entraînement\n",
        "    running_loss = 0.0\n",
        "    epoch_labels = []\n",
        "    epoch_preds = []\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)  # Déplacer les données sur le GPU si disponible\n",
        "\n",
        "        optimizer.zero_grad()  # Réinitialiser les gradients\n",
        "        outputs = model(inputs)  # Faire une prédiction\n",
        "        loss = criterion(outputs, labels)  # Calculer la perte\n",
        "        loss.backward()  # Propagation arrière\n",
        "        optimizer.step()  # Mettre à jour les poids\n",
        "\n",
        "        running_loss += loss.item()  # Ajouter la perte à la somme des pertes\n",
        "\n",
        "        # Sauvegarder les prédictions et les labels pour le calcul de l'accuracy et du F1 score\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        epoch_labels.extend(labels.cpu().numpy())\n",
        "        epoch_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Calcul des métriques pour cette époque\n",
        "    accuracy = 100 * (sum(np.array(epoch_labels) == np.array(epoch_preds)) / len(epoch_labels))\n",
        "    f1 = f1_score(epoch_labels, epoch_preds, average='weighted')\n",
        "\n",
        "    print(f\"Époque [{epoch+1}/{num_epochs}], Perte: {running_loss / len(trainloader):.4f}, \"\n",
        "          f\"Accuracy: {accuracy:.2f}%, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Enregistrer le temps total d'entraînement\n",
        "training_time = time.time() - start_time\n",
        "print(f\"\\nTemps d'entraînement total : {training_time / 60:.2f} minutes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViYXZQOxBloi",
        "outputId": "01fa7186-633e-44d2-f8a6-1a14dcaff875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Précision du modèle sur les données de test : 99.02%\n"
          ]
        }
      ],
      "source": [
        "# Tester le modèle sur le jeu de données de test\n",
        "model.eval()  # Passer le modèle en mode évaluation\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():  # Ne pas calculer les gradients pendant l'évaluation\n",
        "    for data in testloader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Précision du modèle sur les données de test : {100 * correct / total:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}